{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:57:41.044457Z",
     "start_time": "2024-04-03T07:57:41.038746Z"
    }
   },
   "id": "c1f5c1bd32430619",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def polynomial(x):\n",
    "    y1 = x[:, 0] * x[:, 1] * x[:, 2] + 1.2 * x[:, 0] * x[:, 4] - 0.1 * x[:, 5] * x[:, 6] * x[:, 7] - 2 * x[:,\n",
    "                                                                                                         0] ** 2 * x[:,\n",
    "                                                                                                                   7] + x[\n",
    "                                                                                                                        :,\n",
    "                                                                                                                        4]\n",
    "    y2 = x[:, 0] * x[:, 4] * x[:, 5] - x[:, 2] * x[:, 3] - 3 * x[:, 1] * x[:, 2] + 2 * x[:, 1] ** 2 * x[:, 3] - 2 * x[:,\n",
    "                                                                                                                    6] * x[\n",
    "                                                                                                                         :,\n",
    "                                                                                                                         7] - 1\n",
    "    y3 = x[:, 2] ** 2 - x[:, 4] * x[:, 6] - 3 * x[:, 0] * x[:, 3] * x[:, 5] - x[:, 0] ** 2 * x[:, 2] * x[:, 4] - 1\n",
    "    y4 = -x[:, 5] ** 3 + 2 * x[:, 0] * x[:, 2] * x[:, 7] - x[:, 0] * x[:, 3] * x[:, 6] - 2 * x[:, 4] ** 2 * x[:, 1] * x[\n",
    "                                                                                                                      :,\n",
    "                                                                                                                      3] - x[\n",
    "                                                                                                                           :,\n",
    "                                                                                                                           7]\n",
    "    y5 = x[:, 0] ** 2 * x[:, 4] - 3 * x[:, 2] * x[:, 3] * x[:, 7] + x[:, 0] * x[:, 1] * x[:, 3] - 3 * x[:, 5] + x[:,\n",
    "                                                                                                                0] ** 2 * x[\n",
    "                                                                                                                          :,\n",
    "                                                                                                                          6] + 2\n",
    "    y6 = x[:, 0] ** 2 * x[:, 2] * x[:, 5] - x[:, 2] * x[:, 4] * x[:, 6] + x[:, 2] * x[:, 3] + 2.2 * x[:, 1] * x[:,\n",
    "                                                                                                              2] ** 2 - 1.1\n",
    "    return np.stack([y1, y2, y3, y4, y5, y6], axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:57:41.054726Z",
     "start_time": "2024-04-03T07:57:41.049709Z"
    }
   },
   "id": "cd39d248cf5c4482",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:57:41.060391Z",
     "start_time": "2024-04-03T07:57:41.055401Z"
    }
   },
   "id": "958fa5a9d100d736",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "Nt = 1000\n",
    "Nv = 100\n",
    "noise_sigma = 0.001\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Generate the input data\n",
    "x_train = np.random.uniform(low=-1, high=1, size=(Nt, 8))\n",
    "x_val = np.random.uniform(low=-1, high=1, size=(Nv, 8))\n",
    "\n",
    "# Generate the output data with noise\n",
    "y_train = polynomial(x_train) + np.random.normal(scale=noise_sigma)\n",
    "y_val = polynomial(x_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:57:41.075078Z",
     "start_time": "2024-04-03T07:57:41.061205Z"
    }
   },
   "id": "715b066879fe3085",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Activation:relu, Learning Rate:0.1, Epoch:1000 \n",
      "\tTraining and validation errors: 0.4189, 0.4102\n",
      "\n",
      " - Activation:relu, Learning Rate:0.1, Epoch:1500 \n",
      "\tTraining and validation errors: 0.4109, 0.4110\n",
      "\n",
      " - Activation:relu, Learning Rate:0.1, Epoch:2250 \n",
      "\tTraining and validation errors: 0.4475, 0.4262\n",
      "\n",
      " - Activation:relu, Learning Rate:0.01, Epoch:1000 \n",
      "\tTraining and validation errors: 0.4116, 0.4408\n",
      "\n",
      " - Activation:relu, Learning Rate:0.01, Epoch:1500 \n",
      "\tTraining and validation errors: 0.4276, 0.4470\n",
      "\n",
      " - Activation:relu, Learning Rate:0.01, Epoch:2250 \n",
      "\tTraining and validation errors: 0.4123, 0.4272\n",
      "\n",
      " - Activation:relu, Learning Rate:0.001, Epoch:1000 \n",
      "\tTraining and validation errors: 0.6761, 0.5218\n",
      "\n",
      " - Activation:relu, Learning Rate:0.001, Epoch:1500 \n",
      "\tTraining and validation errors: 0.6906, 0.5304\n",
      "\n",
      " - Activation:relu, Learning Rate:0.001, Epoch:2250 \n",
      "\tTraining and validation errors: 0.6286, 0.4886\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.1, Epoch:1000 \n",
      "\tTraining and validation errors: 0.3740, 0.3865\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.1, Epoch:1500 \n",
      "\tTraining and validation errors: 0.3797, 0.3562\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.1, Epoch:2250 \n",
      "\tTraining and validation errors: 0.3644, 0.4170\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.01, Epoch:1000 \n",
      "\tTraining and validation errors: 0.3934, 0.3621\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.01, Epoch:1500 \n",
      "\tTraining and validation errors: 0.3652, 0.4034\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.01, Epoch:2250 \n",
      "\tTraining and validation errors: 0.3831, 0.4033\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.001, Epoch:1000 \n",
      "\tTraining and validation errors: 0.6706, 0.4939\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.001, Epoch:1500 \n",
      "\tTraining and validation errors: 0.6033, 0.5012\n",
      "\n",
      " - Activation:tanh, Learning Rate:0.001, Epoch:2250 \n",
      "\tTraining and validation errors: 0.6104, 0.5130\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.1, Epoch:1000 \n",
      "\tTraining and validation errors: 0.4583, 0.4584\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.1, Epoch:1500 \n",
      "\tTraining and validation errors: 0.4607, 0.4835\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.1, Epoch:2250 \n",
      "\tTraining and validation errors: 0.3817, 0.4198\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.01, Epoch:1000 \n",
      "\tTraining and validation errors: 0.7820, 0.6317\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.01, Epoch:1500 \n",
      "\tTraining and validation errors: 0.7002, 0.5304\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.01, Epoch:2250 \n",
      "\tTraining and validation errors: 0.7560, 0.5918\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.001, Epoch:1000 \n",
      "\tTraining and validation errors: 1.3462, 1.1671\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.001, Epoch:1500 \n",
      "\tTraining and validation errors: 1.3464, 1.1625\n",
      "\n",
      " - Activation:sigmoid, Learning Rate:0.001, Epoch:2250 \n",
      "\tTraining and validation errors: 1.2918, 1.1248\n",
      "\n",
      "Best parameters: {'mdoel': <Sequential name=sequential_41, built=True>, 'activation': 'tanh', 'learning_rate': 0.1, 'epoch': 1500}\n"
     ]
    }
   ],
   "source": [
    "def build_model(hidden_layer_nodes, activation_fn):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(6))\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, x_train, y_train, x_val, y_val, learning_rate, epochs):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=mse_loss, metrics=['mae'])\n",
    "    history = model.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_data=(x_val, y_val), verbose=0)\n",
    "    return history\n",
    "\n",
    "\n",
    "# Train the model with various configurations\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "epochs = [1000, 1500, 2250]\n",
    "\n",
    "best_params = None\n",
    "best_val_loss = 1.0  # set initial loss\n",
    "\n",
    "for activation in activations:\n",
    "    for learning_rate in learning_rates:\n",
    "        for epoch in epochs:\n",
    "            model = build_model(6, activation)\n",
    "            history = train_model(model, x_train, y_train, x_val, y_val, learning_rate, epoch)\n",
    "            print(\n",
    "                f'\\n - Activation:{activation}, Learning Rate:{learning_rate}, Epoch:{epoch} \\n\\tTraining and validation errors: {history.history[\"loss\"][-1]:.4f}, {history.history[\"val_loss\"][-1]:.4f}')\n",
    "\n",
    "            val_loss = history.history[\"val_loss\"][-1]\n",
    "            if val_loss < best_val_loss:\n",
    "                best_params = {'mdoel': model, 'activation': activation, 'learning_rate': learning_rate, 'epoch': epoch}\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "print(f'\\nBest parameters: {best_params}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T08:22:58.966787Z",
     "start_time": "2024-04-03T07:57:41.075728Z"
    }
   },
   "id": "d110277df35a0a99",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 8"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8be4429176f65181"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_nodes_to_hidden_layers(model, x_train, y_train, x_val, y_val, learning_rate, epochs, nodes_to_add, num_hidden_layers):\n",
    "    for i in range(num_hidden_layers):\n",
    "        for j in range(nodes_to_add):\n",
    "            # model.add(layers.Dense(num_hidden_layers + 1, activation=activation)) # compare to below two rows\n",
    "            model.layers[i+1].add(layers.Dense(6 + j + 1, activation=activation))\n",
    "            model.layers[i+1].add(layers.Dense(6 + j + 1))\n",
    "            \n",
    "            history = train_model(model, x_train, y_train, x_val, y_val, learning_rate, epochs)\n",
    "            print(f'Training and validation errors with {num_hidden_layers + 1} nodes in layer {i + 1}: {history.history[\"loss\"][-1]:.4f}, {history.history[\"val_loss\"][-1]:.4f}')\n",
    "            return history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T22:06:17.725907Z",
     "start_time": "2024-04-03T22:06:17.720616Z"
    }
   },
   "id": "2fe588804f77fcad",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_curve(result):\n",
    "    \n",
    "    num_samples = len(result['loss'])\n",
    "    train_loss = np.array(result['loss'])\n",
    "    bias = np.mean(train_loss[:num_samples//2])\n",
    "    variance = np.var(train_loss[num_samples//2:])\n",
    "    \n",
    "    # Plot the bias-variance curve\n",
    "    plt.plot([0, num_samples], [bias, bias], 'k--', label='Bias')\n",
    "    plt.plot([0, num_samples], [variance, variance], 'k:', label='Variance')\n",
    "    plt.plot(result['loss'], '-o', label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Bias-Variance Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dee246d0b99a313"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result1 = add_nodes_to_hidden_layers(best_params.model, x_train, y_train, x_val, y_val, best_params.learning_rate, epochs, 2, 1).history\n",
    "result2 = add_nodes_to_hidden_layers(best_params.model, x_train, y_train, x_val, y_val, best_params.learning_rate, epochs, 2, 2).history\n",
    "result3 = add_nodes_to_hidden_layers(best_params.model, x_train, y_train, x_val, y_val, best_params.learning_rate, epochs, 2, 3).history\n",
    "\n",
    "plot_curve(result1)\n",
    "plot_curve(result2)\n",
    "plot_curve(result3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c637428c852a42e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 9"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "448643598e9fde1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_nodes_with_training(model, x_train, y_train, x_val, y_val, learning_rate, epochs, nodes_to_add,\n",
    "                            hidden_layer_nodes):\n",
    "    for i in range(3):\n",
    "        for j in range(nodes_to_add):\n",
    "            model.add(layers.Dense(hidden_layer_nodes + 1, activation=activation))\n",
    "            history = train_model(model, x_train, y_train, x_val, y_val, learning_rate, epochs)\n",
    "            print(\n",
    "                f'Training and validation errors with {hidden_layer_nodes + 1} nodes in layer {i + 1}: {history.history[\"loss\"][-1]:.4f}, {history.history[\"val_loss\"][-1]:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T08:22:58.970659Z",
     "start_time": "2024-04-03T08:22:58.967847Z"
    }
   },
   "id": "c0eaf168b703bd02",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1100,6) (1000,6) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m Nv \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m110\u001B[39m\n\u001B[1;32m      3\u001B[0m x_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(low\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, high\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, size\u001B[38;5;241m=\u001B[39m(Nt, \u001B[38;5;241m8\u001B[39m))\n\u001B[0;32m----> 4\u001B[0m y_train \u001B[38;5;241m=\u001B[39m polynomial(x_train) \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal(scale\u001B[38;5;241m=\u001B[39mnoise_sigma, size\u001B[38;5;241m=\u001B[39my_train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      5\u001B[0m x_val \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(low\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, high\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, size\u001B[38;5;241m=\u001B[39m(Nv, \u001B[38;5;241m8\u001B[39m))\n\u001B[1;32m      6\u001B[0m y_val \u001B[38;5;241m=\u001B[39m polynomial(x_val)\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (1100,6) (1000,6) "
     ]
    }
   ],
   "source": [
    "Nt = 1100\n",
    "Nv = 110\n",
    "x_train = np.random.uniform(low=-1, high=1, size=(Nt, 8))\n",
    "y_train = polynomial(x_train) + np.random.normal(scale=noise_sigma, size=y_train.shape)\n",
    "x_val = np.random.uniform(low=-1, high=1, size=(Nv, 8))\n",
    "y_val = polynomial(x_val)\n",
    "\n",
    "add_nodes_with_training(best_params.model, x_train, y_train, x_val, y_val, best_params.learning_rate, epochs, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T08:22:58.984309Z",
     "start_time": "2024-04-03T08:22:58.971196Z"
    }
   },
   "id": "86ca45fe1672c40d",
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
