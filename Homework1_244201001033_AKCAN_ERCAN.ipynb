{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1f5c1bd32430619",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def polynomial(x):\n",
    "    y1 = x[:, 0] * x[:, 1] * x[:, 2] + 1.2 * x[:, 0] * x[:, 4] - 0.1 * x[:, 5] * x[:, 6] * x[:, 7] - 2 * x[:, 0]**2 * x[:, 7] + x[:, 4]\n",
    "    y2 = x[:, 0] * x[:, 4] * x[:, 5] - x[:, 2] * x[:, 3] - 3 * x[:, 1] * x[:, 2] + 2 * x[:, 1]**2 * x[:, 3] - 2 * x[:, 6] * x[:, 7] - 1\n",
    "    y3 = x[:, 2]**2 - x[:, 4] * x[:, 6] - 3 * x[:, 0] * x[:, 3] * x[:, 5] - x[:, 0]**2 * x[:, 2] * x[:, 4] - 1\n",
    "    y4 = -x[:, 5]**3 + 2 * x[:, 0] * x[:, 2] * x[:, 7] - x[:, 0] * x[:, 3] * x[:, 6] - 2 * x[:, 4]**2 * x[:, 1] * x[:, 3] - x[:, 7]\n",
    "    y5 = x[:, 0]**2 * x[:, 4] - 3 * x[:, 2] * x[:, 3] * x[:, 7] + x[:, 0] * x[:, 1] * x[:, 3] - 3 * x[:, 5] + x[:, 0]**2 * x[:, 6] + 2\n",
    "    y6 = x[:, 0]**2 * x[:, 2] * x[:, 5] - x[:, 2] * x[:, 4] * x[:, 6] + x[:, 2] * x[:, 3] + 2.2 * x[:, 1] * x[:, 2]**2 - 1.1\n",
    "    return np.stack([y1, y2, y3, y4, y5, y6], axis=-1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd39d248cf5c4482",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "958fa5a9d100d736",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "Nt = 1000\n",
    "Nv = 100\n",
    "noise_sigma = 0.001\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Generate the input data\n",
    "x_train = np.random.uniform(low=-1, high=1, size=(Nt, 8))\n",
    "x_val = np.random.uniform(low=-1, high=1, size=(Nv, 8))\n",
    "\n",
    "# Generate the output data with noise\n",
    "y_train = polynomial(x_train) + np.random.normal(scale=noise_sigma)\n",
    "y_val = polynomial(x_val)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "715b066879fe3085",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_model(hidden_layer_nodes, activation_fn):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(6))\n",
    "    return model\n",
    "\n",
    "def build_model_with_nodes(hidden_layer1_nodes,hidden_layer2_nodes,hidden_layer3_nodes, activation_fn):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_layer1_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer2_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer3_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(6))\n",
    "    return model\n",
    "\n",
    "def train_model(model, x_train, y_train, x_val, y_val, learning_rate, epochs):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=mse_loss, metrics=['mae'])\n",
    "    history = model.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_data=(x_val, y_val), verbose=0)\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ab87242fcfbd8b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train the model with various configurations\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "epochs = [1000, 1500, 2250]\n",
    "\n",
    "best_params = None\n",
    "best_val_loss = 1.0  # set initial loss\n",
    "\n",
    "for activation in activations:\n",
    "    for learning_rate in learning_rates:\n",
    "        for epoch in epochs:\n",
    "            model = build_model(6, activation)\n",
    "            history = train_model(model, x_train, y_train, x_val, y_val, learning_rate, epoch)\n",
    "            print(\n",
    "                f'\\n - Activation:{activation}, Learning Rate:{learning_rate}, Epoch:{epoch} \\n\\tTraining and validation errors: {history.history[\"loss\"][-1]:.4f}, {history.history[\"val_loss\"][-1]:.4f}')\n",
    "\n",
    "            val_loss = history.history[\"val_loss\"][-1]\n",
    "            if val_loss < best_val_loss:\n",
    "                best_params = {'activation': activation, 'learning_rate': learning_rate, 'epoch': epoch}\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "print(f'\\nBest parameters: {best_params}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d110277df35a0a99",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 8"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8be4429176f65181"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_variance_bias_curve(history):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('M')\n",
    "    plt.ylabel('Prediction Error')\n",
    "    plt.xlabel('Complexity')\n",
    "    plt.legend(['Training Samples', 'Test Samples'], loc='upper left')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dee246d0b99a313",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model1 = build_model_with_nodes(8, 6, 6, best_params.get(\"activation\"))\n",
    "history1 = train_model(model1, x_train, y_train, x_val, y_val, best_params.get(\"learning_rate\"), best_params.get(\"epoch\"))\n",
    "\n",
    "model2 = build_model_with_nodes(6, 8, 6, best_params.get(\"activation\"))\n",
    "history2 = train_model(model2, x_train, y_train, x_val, y_val, best_params.get(\"learning_rate\"), best_params.get(\"epoch\"))\n",
    "\n",
    "model3 = build_model_with_nodes(6, 6, 8, best_params.get(\"activation\"))\n",
    "history3 = train_model(model3, x_train, y_train, x_val, y_val, best_params.get(\"learning_rate\"), best_params.get(\"epoch\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c637428c852a42e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_variance_bias_curve(history1)\n",
    "plot_variance_bias_curve(history2)\n",
    "plot_variance_bias_curve(history3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bdcd81d6b919f6e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 9"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "448643598e9fde1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Nt = 1100\n",
    "Nv = 110\n",
    "noise_sigma = 0.001\n",
    "\n",
    "x_train = np.random.uniform(low=-1, high=1, size=(Nt, 8))\n",
    "x_val = np.random.uniform(low=-1, high=1, size=(Nv, 8))\n",
    "\n",
    "y_train = polynomial(x_train) + np.random.normal(scale=noise_sigma)\n",
    "y_val = polynomial(x_val)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86ca45fe1672c40d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model1 = build_model_with_nodes(8, 6, 6, best_params.get(\"activation\"))\n",
    "history1 = train_model(model1, x_train, y_train, x_val, y_val, best_params.get(\"learning_rate\"), best_params.get(\"epoch\"))\n",
    "\n",
    "model2 = build_model_with_nodes(6, 8, 6, best_params.get(\"activation\"))\n",
    "history2 = train_model(model2, x_train, y_train, x_val, y_val, best_params.get(\"learning_rate\"), best_params.get(\"epoch\"))\n",
    "\n",
    "model3 = build_model_with_nodes(6, 6, 8, best_params.get(\"activation\"))\n",
    "history3 = train_model(model3, x_train, y_train, x_val, y_val, best_params.get(\"learning_rate\"), best_params.get(\"epoch\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5408f9573993fc8c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_variance_bias_curve(history1)\n",
    "plot_variance_bias_curve(history2)\n",
    "plot_variance_bias_curve(history3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1408e59faf6307ac",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
