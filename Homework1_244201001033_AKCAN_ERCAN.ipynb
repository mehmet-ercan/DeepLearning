{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1f5c1bd32430619",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def polynomial(x):\n",
    "    y1 = x[:, 0] * x[:, 1] * x[:, 2] + 1.2 * x[:, 0] * x[:, 4] - 0.1 * x[:, 5] * x[:, 6] * x[:, 7] - 2 * x[:, 0]**2 * x[:, 7] + x[:, 4]\n",
    "    y2 = x[:, 0] * x[:, 4] * x[:, 5] - x[:, 2] * x[:, 3] - 3 * x[:, 1] * x[:, 2] + 2 * x[:, 1]**2 * x[:, 3] - 2 * x[:, 6] * x[:, 7] - 1\n",
    "    y3 = x[:, 2]**2 - x[:, 4] * x[:, 6] - 3 * x[:, 0] * x[:, 3] * x[:, 5] - x[:, 0]**2 * x[:, 2] * x[:, 4] - 1\n",
    "    y4 = -x[:, 5]**3 + 2 * x[:, 0] * x[:, 2] * x[:, 7] - x[:, 0] * x[:, 3] * x[:, 6] - 2 * x[:, 4]**2 * x[:, 1] * x[:, 3] - x[:, 7]\n",
    "    y5 = x[:, 0]**2 * x[:, 4] - 3 * x[:, 2] * x[:, 3] * x[:, 7] + x[:, 0] * x[:, 1] * x[:, 3] - 3 * x[:, 5] + x[:, 0]**2 * x[:, 6] + 2\n",
    "    y6 = x[:, 0]**2 * x[:, 2] * x[:, 5] - x[:, 2] * x[:, 4] * x[:, 6] + x[:, 2] * x[:, 3] + 2.2 * x[:, 1] * x[:, 2]**2 - 1.1\n",
    "    return np.stack([y1, y2, y3, y4, y5, y6], axis=-1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd39d248cf5c4482",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "958fa5a9d100d736",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "Nt = 1000\n",
    "Nv = 100\n",
    "noise_sigma = 0.001\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Generate the input data\n",
    "x_train = np.random.uniform(low=-1, high=1, size=(Nt, 8))\n",
    "x_val = np.random.uniform(low=-1, high=1, size=(Nv, 8))\n",
    "\n",
    "# Generate the output data with noise\n",
    "y_train = polynomial(x_train) + np.random.normal(scale=noise_sigma)\n",
    "y_val = polynomial(x_val)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "715b066879fe3085",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'Sequential'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 24\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m learning_rate \u001B[38;5;129;01min\u001B[39;00m learning_rates:\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m epochs:\n\u001B[0;32m---> 24\u001B[0m         model \u001B[38;5;241m=\u001B[39m build_model(\u001B[38;5;241m6\u001B[39m, activation)\n\u001B[1;32m     25\u001B[0m         history \u001B[38;5;241m=\u001B[39m train_model(model, x_train, y_train, x_val, y_val, learning_rate, epoch)\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m - Activation:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mactivation\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Learning Rate:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlearning_rate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Epoch:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mTraining and validation errors: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhistory\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhistory\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m, in \u001B[0;36mbuild_model\u001B[0;34m(hidden_layer_nodes, activation_fn)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild_model\u001B[39m(hidden_layer_nodes, activation_fn):\n\u001B[0;32m----> 2\u001B[0m     model \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39mSequential()\n\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mDense(hidden_layer_nodes, activation\u001B[38;5;241m=\u001B[39mactivation_fn))\n\u001B[1;32m      4\u001B[0m     model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mDense(hidden_layer_nodes, activation\u001B[38;5;241m=\u001B[39mactivation_fn))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'Sequential'"
     ]
    }
   ],
   "source": [
    "def build_model(hidden_layer_nodes, activation_fn):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(hidden_layer_nodes, activation=activation_fn))\n",
    "    model.add(layers.Dense(6))\n",
    "    return model\n",
    "\n",
    "def train_model(model, x_train, y_train, x_val, y_val, learning_rate, epochs):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=mse_loss, metrics=['mae'])\n",
    "    history = model.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_data=(x_val, y_val), verbose=0)\n",
    "    return history\n",
    "\n",
    "# Train the model with various configurations\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "epochs = [1000, 1500, 2250]\n",
    "models = []\n",
    "\n",
    "for activation in activations:\n",
    "    for learning_rate in learning_rates:\n",
    "        for epoch in epochs:\n",
    "            model = build_model(6, activation)\n",
    "            history = train_model(model, x_train, y_train, x_val, y_val, learning_rate, epoch)\n",
    "            print(f'\\n - Activation:{activation}, Learning Rate:{learning_rate}, Epoch:{epoch} \\n\\tTraining and validation errors: {history.history[\"loss\"][-1]:.4f}, {history.history[\"val_loss\"][-1]:.4f}')\n",
    "            models.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T00:39:54.061083Z",
     "start_time": "2024-04-03T00:39:54.034687Z"
    }
   },
   "id": "d110277df35a0a99",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_nodes_with_training(model, x_train, y_train, x_val, y_val, learning_rate, epochs, nodes_to_add, hidden_layer_nodes):\n",
    "    for i in range(3):\n",
    "        for j in range(nodes_to_add):\n",
    "            model.add(layers.Dense(hidden_layer_nodes + 1, activation=activation))\n",
    "            history = train_model(model, x_train, y_train, x_val, y_val, learning_rate, epochs)\n",
    "            print(f'Training and validation errors with {hidden_layer_nodes + 1} nodes in layer {i + 1}: {history.history[\"loss\"][-1]:.4f}, {history.history[\"val_loss\"][-1]:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0eaf168b703bd02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Select Model\n",
    "best_model = models[0]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87aa84b81169f94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 8"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d5868aff9d10621"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "add_nodes_with_training(best_model, x_train, y_train, x_val, y_val, learning_rate, epochs, 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e436c56f4b1d61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 9"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "448643598e9fde1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Nt = 1100\n",
    "Nv = 110\n",
    "x_train = np.random.uniform(low=-1, high=1, size=(Nt, 8))\n",
    "y_train = polynomial(x_train) + np.random.normal(scale=noise_sigma, size=y_train.shape)\n",
    "x_val = np.random.uniform(low=-1, high=1, size=(Nv, 8))\n",
    "y_val = polynomial(x_val)\n",
    "\n",
    "add_nodes_with_training(model, x_train, y_train, x_val, y_val, learning_rate, epochs, 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86ca45fe1672c40d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
